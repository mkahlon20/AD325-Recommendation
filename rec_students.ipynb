{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "# Load data: user_id -> set of item_ids\n",
    "def load_data(file_path):\n",
    "    user_item_data = {}\n",
    "\n",
    "    with open(file_path, newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # skip header row\n",
    "\n",
    "        for user_id, item_id in reader:\n",
    "            if user_id not in user_item_data:\n",
    "                user_item_data[user_id] = set()\n",
    "            user_item_data[user_id].add(item_id)\n",
    "\n",
    "    return user_item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashTable:\n",
    "    def __init__(self, size, collision_avoidance):\n",
    "        # For separate chaining: each slot is a list (bucket)\n",
    "        # For probing: each slot is either None or (key, [items])\n",
    "        if collision_avoidance == \"separate_chaining\":\n",
    "            self.table = [[] for _ in range(size)]\n",
    "        else:\n",
    "            self.table = [None] * size\n",
    "\n",
    "        self.size = size\n",
    "        self.collisions = 0\n",
    "        self.collision_avoidance = collision_avoidance\n",
    "        self.count = 0  # number of keys stored\n",
    "\n",
    "    def hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "\n",
    "    # Provided for completeness; not used for separate_chaining/linear_probing\n",
    "    def second_hash(self, key):\n",
    "        return 1 + (hash(key) % (self.size - 1))\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        \"\"\"\n",
    "        Insert a (user, item) pair.\n",
    "        If user already exists, add item to their list.\n",
    "        \"\"\"\n",
    "        index = self.hash(key)\n",
    "\n",
    "        if self.collision_avoidance == \"separate_chaining\":\n",
    "            bucket = self.table[index]\n",
    "\n",
    "            # Look for existing key\n",
    "            for i, (k, items) in enumerate(bucket):\n",
    "                if k == key:\n",
    "                    if value not in items:\n",
    "                        items.append(value)\n",
    "                        bucket[i] = (k, items)\n",
    "                    return\n",
    "\n",
    "            # No key found — insert new\n",
    "            if len(bucket) > 0:\n",
    "                self.collisions += 1  # bucket already had something\n",
    "\n",
    "            bucket.append((key, [value]))\n",
    "            self.count += 1\n",
    "\n",
    "        elif self.collision_avoidance == \"linear_probing\":\n",
    "            original_index = index\n",
    "\n",
    "            while True:\n",
    "                entry = self.table[index]\n",
    "\n",
    "                if entry is None:\n",
    "                    # Insert new key here\n",
    "                    self.table[index] = (key, [value])\n",
    "                    self.count += 1\n",
    "                    return\n",
    "\n",
    "                existing_key, items = entry\n",
    "\n",
    "                if existing_key == key:\n",
    "                    # Same key — add item if not already present\n",
    "                    if value not in items:\n",
    "                        items.append(value)\n",
    "                        self.table[index] = (existing_key, items)\n",
    "                    return\n",
    "\n",
    "                # Collision with a different key\n",
    "                self.collisions += 1\n",
    "                index = (index + 1) % self.size\n",
    "\n",
    "                if index == original_index:\n",
    "                    raise RuntimeError(\"HashTable is full during insert.\")\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown collision avoidance technique.\")\n",
    "\n",
    "    def retrieve(self, key):\n",
    "        \"\"\"\n",
    "        Return list of items stored for this user.\n",
    "        \"\"\"\n",
    "        index = self.hash(key)\n",
    "\n",
    "        if self.collision_avoidance == \"separate_chaining\":\n",
    "            bucket = self.table[index]\n",
    "            for (k, items) in bucket:\n",
    "                if k == key:\n",
    "                    return items\n",
    "            return []\n",
    "\n",
    "        elif self.collision_avoidance == \"linear_probing\":\n",
    "            original_index = index\n",
    "\n",
    "            while True:\n",
    "                entry = self.table[index]\n",
    "                if entry is None:\n",
    "                    return []\n",
    "\n",
    "                existing_key, items = entry\n",
    "                if existing_key == key:\n",
    "                    return items\n",
    "\n",
    "                index = (index + 1) % self.size\n",
    "                if index == original_index:\n",
    "                    return []\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown collision avoidance technique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxHeap:\n",
    "    def __init__(self):\n",
    "        self.heap = []\n",
    "\n",
    "    def parent(self, index):\n",
    "        return (index - 1) // 2\n",
    "\n",
    "    def left_child(self, index):\n",
    "        return 2 * index + 1\n",
    "\n",
    "    def right_child(self, index):\n",
    "        return 2 * index + 2\n",
    "\n",
    "    def has_left(self, index):\n",
    "        return self.left_child(index) < len(self.heap)\n",
    "\n",
    "    def has_right(self, index):\n",
    "        return self.right_child(index) < len(self.heap)\n",
    "\n",
    "    def swap(self, i, j):\n",
    "        self.heap[i], self.heap[j] = self.heap[j], self.heap[i]\n",
    "\n",
    "    def percolate_up(self, index):\n",
    "        parent = self.parent(index)\n",
    "        if index > 0 and self.heap[index][0] > self.heap[parent][0]:\n",
    "            self.swap(index, parent)\n",
    "            self.percolate_up(parent)\n",
    "\n",
    "    def percolate_down(self, index):\n",
    "        largest = index\n",
    "        left = self.left_child(index)\n",
    "        right = self.right_child(index)\n",
    "\n",
    "        if self.has_left(index) and self.heap[left][0] > self.heap[largest][0]:\n",
    "            largest = left\n",
    "        if self.has_right(index) and self.heap[right][0] > self.heap[largest][0]:\n",
    "            largest = right\n",
    "        if largest != index:\n",
    "            self.swap(index, largest)\n",
    "            self.percolate_down(largest)\n",
    "\n",
    "    def push(self, priority, item):\n",
    "        self.heap.append((priority, item))\n",
    "        self.percolate_up(len(self.heap) - 1)\n",
    "\n",
    "    def pop(self):\n",
    "        if len(self.heap) == 0:\n",
    "            return None\n",
    "        if len(self.heap) == 1:\n",
    "            return self.heap.pop()\n",
    "\n",
    "        self.swap(0, len(self.heap) - 1)\n",
    "        item = self.heap.pop()\n",
    "        self.percolate_down(0)\n",
    "        return item\n",
    "\n",
    "    def top_n(self, n):\n",
    "        top_items = []\n",
    "        count = min(n, len(self.heap))\n",
    "        for _ in range(count):\n",
    "            priority, item = self.pop()\n",
    "            top_items.append(item)\n",
    "        return top_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    def __init__(self, user_item_file):\n",
    "        # Load user -> set of items from the CSV file\n",
    "        self.user_item_file = user_item_file\n",
    "        self.user_item_data = load_data(user_item_file)\n",
    "\n",
    "    def build_recommendation_system(self, technique, size):\n",
    "        \"\"\"\n",
    "        Build the hash table for the given collision technique.\n",
    "        Returns the hash table and insertion time.\n",
    "        \"\"\"\n",
    "        hash_table = HashTable(size, technique)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Insert all (user, item) pairs\n",
    "        for user, items in self.user_item_data.items():\n",
    "            for item in items:\n",
    "                hash_table.insert(user, item)\n",
    "\n",
    "        end_time = time.time()\n",
    "        insertion_time = end_time - start_time\n",
    "\n",
    "        return hash_table, insertion_time\n",
    "\n",
    "    def recommend_items_with_jaccard(self, target_user, technique, top_n):\n",
    "        \"\"\"\n",
    "        Make recommendations for target_user using:\n",
    "        - HashTable (technique)\n",
    "        - Jaccard similarity\n",
    "        - MaxHeap\n",
    "\n",
    "        Returns: (recommendations, insertion_time, retrieval_time, collisions)\n",
    "        \"\"\"\n",
    "        table_size = 20  # small data, simple size\n",
    "\n",
    "        # 1. Build hash table\n",
    "        hash_table, insertion_time = self.build_recommendation_system(\n",
    "            technique, table_size\n",
    "        )\n",
    "\n",
    "        # 2. Compute similarities and item scores\n",
    "        start_time = time.time()\n",
    "\n",
    "        target_items = set(hash_table.retrieve(target_user))\n",
    "\n",
    "        item_scores = {}  # item -> accumulated similarity\n",
    "\n",
    "        for user, items_from_dict in self.user_item_data.items():\n",
    "            if user == target_user:\n",
    "                continue\n",
    "\n",
    "            other_items = set(hash_table.retrieve(user))\n",
    "\n",
    "            # Jaccard similarity\n",
    "            intersection = target_items.intersection(other_items)\n",
    "            union = target_items.union(other_items)\n",
    "\n",
    "            if len(union) == 0:\n",
    "                similarity = 0.0\n",
    "            else:\n",
    "                similarity = len(intersection) / len(union)\n",
    "\n",
    "            if similarity == 0:\n",
    "                continue\n",
    "\n",
    "            # Accumulate scores for items the target user does NOT already own\n",
    "            for item in other_items:\n",
    "                if item in target_items:\n",
    "                    # DO NOT recommend items they already own\n",
    "                    continue\n",
    "\n",
    "                if item not in item_scores:\n",
    "                    item_scores[item] = 0.0\n",
    "                item_scores[item] += similarity\n",
    "\n",
    "        # 3. Push items into MaxHeap\n",
    "        heap = MaxHeap()\n",
    "        for item, score in item_scores.items():\n",
    "            heap.push(score, item)\n",
    "\n",
    "        recommendations = heap.top_n(top_n)\n",
    "\n",
    "        end_time = time.time()\n",
    "        retrieval_time = end_time - start_time\n",
    "\n",
    "        collisions = hash_table.collisions\n",
    "\n",
    "        return recommendations, insertion_time, retrieval_time, collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running recommendations for target user: user1\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user1: ['The Last of Us', 'Battlefield', 'Gears of War']\n",
      "Insertion Time: 0.000114 seconds\n",
      "Retrieval Time: 0.000219 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user1: ['The Last of Us', 'Battlefield', 'Gears of War']\n",
      "Insertion Time: 0.000071 seconds\n",
      "Retrieval Time: 0.000092 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user2\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user2: ['Bayonetta', 'Splatoon', 'Gears of War']\n",
      "Insertion Time: 0.000081 seconds\n",
      "Retrieval Time: 0.000075 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user2: ['Bayonetta', 'Splatoon', 'Gears of War']\n",
      "Insertion Time: 0.000062 seconds\n",
      "Retrieval Time: 0.000071 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user3\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user3: ['League of Legends', 'Resident Evil', 'Bayonetta']\n",
      "Insertion Time: 0.000069 seconds\n",
      "Retrieval Time: 0.000068 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user3: ['League of Legends', 'Resident Evil', 'Bayonetta']\n",
      "Insertion Time: 0.000061 seconds\n",
      "Retrieval Time: 0.000069 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user4\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user4: ['Silent Hill', 'Half-Life', 'Splatoon']\n",
      "Insertion Time: 0.000080 seconds\n",
      "Retrieval Time: 0.000084 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user4: ['Silent Hill', 'Half-Life', 'Splatoon']\n",
      "Insertion Time: 0.000082 seconds\n",
      "Retrieval Time: 0.000085 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user5\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user5: ['Bayonetta', 'Resident Evil', 'Half-Life']\n",
      "Insertion Time: 0.000072 seconds\n",
      "Retrieval Time: 0.000081 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user5: ['Bayonetta', 'Resident Evil', 'Half-Life']\n",
      "Insertion Time: 0.000071 seconds\n",
      "Retrieval Time: 0.000077 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user6\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user6: ['Red Dead Redemption 2', 'World of Warcraft', 'Dragon Age']\n",
      "Insertion Time: 0.000078 seconds\n",
      "Retrieval Time: 0.000086 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user6: ['Red Dead Redemption 2', 'World of Warcraft', 'Dragon Age']\n",
      "Insertion Time: 0.000075 seconds\n",
      "Retrieval Time: 0.000079 seconds\n",
      "Collisions: 37\n",
      "\n",
      "\n",
      "Running recommendations for target user: user7\n",
      "\n",
      "Using collision avoidance technique: separate_chaining\n",
      "Recommendations for user7: ['Bioshock', 'Super Mario Bros', 'Animal Crossing']\n",
      "Insertion Time: 0.000126 seconds\n",
      "Retrieval Time: 0.000087 seconds\n",
      "Collisions: 1\n",
      "\n",
      "Using collision avoidance technique: linear_probing\n",
      "Recommendations for user7: ['Bioshock', 'Super Mario Bros', 'Animal Crossing']\n",
      "Insertion Time: 0.000074 seconds\n",
      "Retrieval Time: 0.000090 seconds\n",
      "Collisions: 37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    user_item_file = \"user_item_data.csv\"\n",
    "\n",
    "    # Create the recommendation system\n",
    "    rec_sys = RecommendationSystem(user_item_file)\n",
    "\n",
    "    # Collision techniques we are comparing\n",
    "    techniques = [\"separate_chaining\", \"linear_probing\"]\n",
    "\n",
    "    # Get list of users from the data\n",
    "    target_users = sorted(rec_sys.user_item_data.keys())\n",
    "\n",
    "    for target_user in target_users:\n",
    "        print(f\"\\nRunning recommendations for target user: {target_user}\\n\")\n",
    "\n",
    "        for technique in techniques:\n",
    "            recommendations, insertion_time, retrieval_time, collisions = \\\n",
    "                rec_sys.recommend_items_with_jaccard(\n",
    "                    target_user=target_user,\n",
    "                    technique=technique,\n",
    "                    top_n=3  # top 3 items\n",
    "                )\n",
    "\n",
    "            print(f\"Using collision avoidance technique: {technique}\")\n",
    "            print(f\"Recommendations for {target_user}: {recommendations}\")\n",
    "            print(f\"Insertion Time: {insertion_time:.6f} seconds\")\n",
    "            print(f\"Retrieval Time: {retrieval_time:.6f} seconds\")\n",
    "            print(f\"Collisions: {collisions}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collision Technique Analysis\n",
    "\n",
    "In my experiments I compared two collision resolution techniques:\n",
    "\n",
    "- **Separate Chaining**\n",
    "- **Linear Probing**\n",
    "\n",
    "### Which had fewer collisions?\n",
    "\n",
    "From the output, **separate chaining** had the fewest collisions (around 1), while **linear probing** had many more (around 30–40).  \n",
    "\n",
    "This makes sense because:\n",
    "\n",
    "- In **separate chaining**, each table slot holds a *bucket* (a small list).  \n",
    "  When a collision happens, the new key just gets added to that list.  \n",
    "  We still count it as a collision, but we do **not** have to move to another index in the table.\n",
    "- In **linear probing**, when a collision happens we keep stepping forward through the array until we find an empty spot.  \n",
    "  This creates *primary clustering*, where groups of occupied cells grow and cause even more collisions as the table fills.\n",
    "\n",
    "So linear probing naturally reports more collisions because it has to search across multiple slots whenever several keys hash to nearby positions.\n",
    "\n",
    "### Strengths and weaknesses\n",
    "\n",
    "**Separate Chaining**\n",
    "\n",
    "- **Strengths**\n",
    "  - Simple to implement.\n",
    "  - Handles high load factors better (the table can be quite full and still work, because extra items just go in the bucket list).\n",
    "  - Fewer clustering issues.\n",
    "- **Weaknesses**\n",
    "  - Uses extra memory for the lists in each bucket.\n",
    "  - Worst-case lookup time can be slower if one bucket’s list gets long.\n",
    "\n",
    "**Linear Probing**\n",
    "\n",
    "- **Strengths**\n",
    "  - Everything is stored directly in the array, so it is memory-friendly and cache-friendly.\n",
    "  - Easy to implement and doesn’t require extra data structures.\n",
    "- **Weaknesses**\n",
    "  - More sensitive to load factor: as the table gets full, performance drops quickly.\n",
    "  - Suffers from clustering, which increases the number of probes and collisions.\n",
    "\n",
    "In my results, this shows up as **many more collisions** for linear probing compared to separate chaining.\n",
    "\n",
    "### Was MaxHeap the best choice?\n",
    "\n",
    "Using a **MaxHeap** for recommendations is a reasonable choice because:\n",
    "\n",
    "- We assign each candidate item a **score** (sum of similarity values).\n",
    "- We want to efficiently get the **top N items** with the highest scores.\n",
    "- A max-heap supports:\n",
    "  - `push` in \\(O(\\log n)\\) time\n",
    "  - `pop` of the max item in \\(O(\\log n)\\) time\n",
    "  - Getting the top \\(N\\) recommendations in \\(O(N \\log n)\\) time\n",
    "\n",
    "Another option would be:\n",
    "\n",
    "- Put all `(score, item)` pairs into a regular **list** and call `sorted(...)` or `list.sort(...)`.  \n",
    "  This is \\(O(n \\log n)\\) and is perfectly fine for small data, but for larger data a heap can be more efficient if we only need the top few elements.\n",
    "- Use a **balanced tree** or **ordered structure**, but that would be more complex to implement by hand.\n",
    "\n",
    "For this project, the **MaxHeap is a good choice** because it matches the idea of “priority recommendations” and lets us practice implementing a heap data structure ourselves. For small datasets, sorting would also work, but the heap gives us better practice with priority queues and aligns with the assignment’s goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
